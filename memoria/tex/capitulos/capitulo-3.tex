%
% ────────────────────────────────────────────────────────────────────────── I ──────────
%   :::::: C A D E N A S   D E   M A R K O V : :  :   :    :     :        :          :
% ────────────────────────────────────────────────────────────────────────────────────
%

\cb{REVIEW: Nada más empezar. El título está bien así o lo llamo `procesos de Markov' o algo similar?}

Hasta este momento, en los dos primeros capítulos, nos hemos centrado totalmente en una introducción teórico-práctica a los polinomios ortogonales y sus principales propiedades, profundizando en las llamadas familias clásicas. En este capítulo explicaremos una teoría probabilística que, aparentemente, nada tiene que ver con los polinomios ortogonales, aunque estudiaremos la estrecha relación que hay entre ambas teorías en el capítulo \ref{chap:POyPNM}.

En concreto, analizaremos desde un punto de vista general los llamados \textit{procesos de Markov, procesos markovianos} o simplemente \textit{cadenas de Markov}. Estos modelos, basados en estados, tratan de explicar las probabilidades de los posibles cambios de estado basándose en un principio denominado \textit{propiedad de Markov}. Esta denominación tanto del modelo como de la propiedad se debe a Andrey Markov, matemático que fue el primero en estudiar, en la década de 1900, los procesos estocásticos con dicha propiedad, que posteriormente se popularizarían.

Nos centraremos principalmente en procesos discretos, es decir, consideramos que el tiempo se divide en instantes $n=0,1,2,\dots$, sin olvidar que existe una teoría análoga en la que el tiempo es continuo $t\in[0,\infty)$. Denominamos \textit{estado} a cualquiera de las situaciones en las que se puede encontrar el sistema en un instante determinado. Por ejemplo, pensemos en una región en la que hay $N$ ciudades y dividimos el tiempo en años. Asumimos que un individuo siempre se encuentra asentado en una de estas ciudades aunque hay posibilidad de que de un año a otro se mude a otra distinta. Etiquetamos cada una de las ciudades con un número: ciudad $1$, ciudad $2$,\dots,ciudad $N$.

\section{Cadenas de Markov discretas. Matriz de transición}

De forma general, consideramos un espacio de estados finito que con frecuencia denotaremos como $S=\{1,\dots, N\}$ y dividimos el tiempo en instantes $n=0,1,2,\dots$. Llamemos $X_n\in S$ al estado del sistema en el instante $n$. La propiedad específica que consideró Markov consiste en asumir que, suponiendo que el sistema se encuentra en un estado concreto en un instante concreto, la probabilidad de que ocurra una transición en el siguiente instante depende única y exclusivamente del estado actual.

\begin{definicion}[Cadena de Markov]
    Un proceso estocástico $\{X_n,n\geq 0\}$ en un espacio de estados $S$ verifica la \textbf{propiedad markoviana} o \textbf{propiedad de Markov} si, para todo $n\in\N_0$ y $j,i,i_{n-1},\dots, i_0 \in S$:
    \begin{equation}
        \label{eq:prop-markow}
        P[X_{n+1}=j | X_n=i, X_{n-1}=i_{n-1}, \dots, X_0=i_0 ] = P[X_{n+1}=j | X_n=i].
    \end{equation}

    En caso de que el proceso cumpla la propiedad (\ref{eq:prop-markow}) se denominará \textbf{cadena de Markov discreta}.

    Una cadena de Markov $\{X_n, n\geq 0\}$ se llamará \textbf{homogénea} si, para todo $n\in\N_0$,
    \begin{equation}
        \label{eq:cad-homogenea}
        P[X_{n+1}=j|X_n=i] = P[X_1=j|X_0=i].
    \end{equation}
\end{definicion}

Es decir, la probabilidad de que en un instante $n+1$ el sistema se encuentre en el estado $j$ es independiente de lo que haya ocurrido en los instantes anteriores a $n$. Por ejemplo, aplicando esta propiedad al tiempo atmosférico podríamos afirmar que la probabilidad de que mañana llueva únicamente depende de si hoy ha llovido, sin tener en cuenta el clima de los días anteriores. En epidemiología, es como afirmar que el número de contagios de una enfermedad únicamente depende del número de contagios que haya habido el día anterior, independientemente del número de contagios de los días anteriores ni los posibles factores externos. Intuitivamente, no parece que esta suposición sea muy realista y no cabe esperar resultados precisos en predicciones futuras. Sin embargo, lo cierto es que es útil para hacernos una idea de lo que puede ocurrir a largo plazo con relativa exactitud y es muy utilizada a la hora de implementar medidas en ámbitos como la migración, la extinción de animales, uso de suelo, etc.

La probabilidad $P[X_{n+1}=j|X_n=i]$ se denomina \textbf{probabilidad de transición en un paso} de la cadena en el instante $n$. Si además la cadena es homogénea, este valor es el mismo para todo instante $n$, de ahí el término `homogénea'. En adelante, cuando utilicemos el término `cadena de Markov' nos estaremos refiriendo a una cadena de Markov homogénea. Una vez anulada la dependencia de $n$, introducimos una nueva notación:
$$
p_{ij} := P[X_{n+1}=j|X_n=i], \ \ \forall i,j \in \{1,\dots,N\}.
$$
Con esta notación, y teniendo en cuenta que en un espacio de $N$ estados existen $N^2$ posibles transiciones, agrupamos todas estas probabilidades en una matriz.

\begin{definicion}[Matriz de transición]
    Llamamos \textbf{matriz de transición} de una cadena de Markov $\{X_n, n\geq 0\}$ a la matriz
    \begin{equation}
        \label{eq:matriz-trans}
        P=\begin{pmatrix}
          p_{11} & p_{12} & \cdots & p_{1N} \\
          p_{21} & p_{22} & \cdots & p_{2N} \\
          \vdots & \vdots & \ddots & \vdots \\
          p_{N1} & p_{N2} & \cdots & p_{NN}  
        \end{pmatrix}.
    \end{equation}
\end{definicion}

\begin{observacion}
    Obsérvese que la $i$-ésima fila corresponde a la distribución de la probabilidad saliente del estado $i$, mientras que la $j$-ésima columna describe la probabilidad entrante al estado $j$.
\end{observacion}

Presentamos a continuación dos propiedades directas de las matrices de transición.

\begin{proposicion}
    \label{prop:propiedades-matrices-markov}
Sea $\{X_n, n\geq 0\}$ una cadena de Markov sobre el espacio de estados $S=\{1,\dots,N\}$ y cuya matriz de transición es $P=(p_{ij})_{i,j=1,\dots,N}$. Entonces
\begin{enumerate}
    \item $0\leq p_{ij} \leq 1 \ \ \ \forall i,j\in S$.
    \item $\sum_{j=1}^N p_{ij} = 1 \ \ \ \forall i\in S$ (todas las filas de $P$ suman 1).
\end{enumerate}
\end{proposicion}
\begin{proof}
    La propiedad (1) es evidente teniendo en cuenta que $p_{ij}$ es una probabilidad. Sobre la propiedad (2), tenemos que
    \begin{equation*}
        \begin{split}
            \sum_{j=1}^N p_{ij} &= \sum_{j=1}^N P[X_{n+1}=j|X_n=i] \\
            &= P[X_{n+1}\in S|X_n=i] \ \ \text{(por el teorema de la probabilidad total)} \\
            &= 1
        \end{split}
    \end{equation*}
\end{proof}

A las matrices que cumplen estas dos propiedades se les denomina \textbf{matrices estocásticas} y pueden ser consideradas matrices de transición de alguna cadena de Markov.

\begin{ejemplo}[Tiempo atmosférico]
    \label{ej:tiempo}
    Extraído de \cite{kulkarni-2012}[Ch. 2, Example 2.3]. Supongamos que podemos clasificar el tiempo de una ciudad como soleado (1), nublado (2) o lluvioso (3) y que el tiempo del día siguiente únicamente depende del tiempo del día anterior con las siguientes probabilidades:
    \begin{itemize}
        \item Si hoy hace sol, mañana estará nublado con probabilidad $0.3$ y lloverá con probabilidad $0.2$.
        \item Si hoy está nublado, mañana hará sol con probabilidad $0.5$ y lloverá con con probabilidad $0.3$.
        \item Si hoy está lloviendo, mañana será un día soleado con probabilidad $0.4$ y nublado con probabilidad $0.5$.
    \end{itemize}

    Modelaremos este sistema mediante una cadena de Markov. Para ello, consideraremos la variable $X_n \equiv$ ``Tiempo atmosférico en el día $n$''. Y consideramos el espacio de estados $S = \{ 1\equiv\text{soleado}, 2\equiv\text{nublado}, 3\equiv\text{lluvioso}\}$. Atendiendo a las indicaciones anteriores y al item (2) de la proposición \ref{prop:propiedades-matrices-markov}, la matriz de transición sería por tanto
    $$ P = \begin{pmatrix}
        0.5 & 0.3 & 0.2 \\
        0.5 & 0.2 & 0.3 \\
        0.4 & 0.5 & 0.1
    \end{pmatrix}.
    $$

\end{ejemplo}

\section{Distribuciones transitorias}

Hasta el momento nos hemos centrado en la adaptación de distintas situaciones de acuerdo a modelos de estados regidos por cadenas de Markov, que en el caso homogéneo concentra toda su información en una matriz estocástica que denominamos matriz de transición. Sin embargo, ya adelantamos en la introducción que la principal función de este método consiste en tratar de predecir el comportamiento de la variable $X_n$ en algún instante futuro. Pongamos el caso del ejemplo \ref{ej:tiempo} sobre el tiempo atmosférico. Podría interesar predecir el tiempo que va a hacer dentro de 2 o 3 días para posponer o no un evento por lluvia. En esta sección estudiaremos cómo podemos utilizar cadenas de Markov con este objetivo.

Sea $\{X_n, n\geq 0\}$ una cadena de Markov discreta y homogénea sobre un espacio de estados $S=\{1,\dots,N\}$, una matriz de transición $P$ y supongamos conocida la distribución inicial, que denotaremos en forma de vector columna como $X_0 = (a_1, \dots, a_N)^T$, donde $a_i = P[X_0 = i]$, $\forall i \in S$. Se denomina \textbf{distribución transitoria} a la distribución que sigue la variable $X_n$ para cierto $n\geq 0$ fijo cuando es conocida la distribución de $X_0$.

Abordemos este problema con lo que conocemos hasta el momento. Tenemos que

\begin{equation}
    \label{eq:distr-trans}
    \begin{split}
        P[X_n = j] &= \sum_{i=1}^N P[X_n=j|X_0 = i]P[X_0=i] \\
        &= a_i \sum_{i=1}^N P[X_n=j|X_0 = i].
    \end{split}
\end{equation}

Por lo que nuestro problema se reduce a encontrar la probabilidad de que el proceso esté en el estado $j$ tras $n$ instantes suponiendo que inicialmente se encontraba en el estado $i$, $P[X_n=j|X_0 = i]$. Esta probabilidad extiende a la que en su momento llamamos probabilidad de transición en un paso y, naturalmente, se denomina \textbf{probabilidad de transición en }$\mathbf{n}$ \textbf{pasos}. Utilizamos la notación  
\begin{align*}
    a_i^{(n)} &:= P[X_n=i], & p_{ij}^{(n)} &:= P[X_{n}=j|X_0=i],
\end{align*}
$\forall i,j \in \{1,\dots,N\}$. De esta forma, buscar la distribución de $X_n$ equivale a buscar la distribución del vector aleatorio $a^{(n)}=(a_1^{(n)},\dots,a_N^{(n)})^T$. Análogamente al caso en el que considerábamos un único paso, agrupamos todos los posibles valores de $p_{ij}^{(n)}$ en una matriz.

\begin{definicion}[Matriz de transición en $n$ pasos]
    Llamamos \textbf{matriz de transición en }$\mathbf{n}$ \textbf{pasos} de una cadena de Markov $\{X_n, n\geq 0\}$ a la matriz
    \begin{equation}
        \label{eq:matriz-trans-n}
        P^{(n)}=\begin{pmatrix}
          p_{11}^{(n)} & p_{12}^{(n)} & \cdots & p_{1N}^{(n)} \\
          p_{21}^{(n)} & p_{22}^{(n)} & \cdots & p_{2N}^{(n)} \\
          \vdots & \vdots & \ddots & \vdots \\
          p_{N1}^{(n)} & p_{N2}^{(n)} & \cdots & p_{NN}^{(n)}  
        \end{pmatrix}.
    \end{equation}
\end{definicion}

\begin{observacion}
    Si tomamos $n=0$, tenemos que $p_{ij}=\delta_{ij}$, $i,j\in S$. Esto es, $P^{(0)}=I_N$. Por otro lado, si $n=1$, tenemos que $P^{(1)}=P$, la matriz de transición (\ref{eq:matriz-trans}).
\end{observacion}

Así, podemos reescribir (\ref{eq:distr-trans}) de forma matricial como
$$
a^{(n)}= P^{(n)} \cdot X_0.
$$

Por lo que resta obtener un método para calcular la matriz de transición en $n$ pasos, $P^{(n)}$. Este método nos lo da el siguiente teorema:

\begin{teorema}[Matriz de transición en $n$ pasos]
    \label{th:matriz-trans-n}
    Sea $\{X_n,n\geq 0\}$ una cadena de Markov homogénea con matriz de transición $P$, entonces
    \begin{equation}
        \label{eq:matriz-trans-n-teorema}
        P^{(n)} = P^n.
    \end{equation}    
\end{teorema}
\begin{proof}
    Consúltese \cite[Ch. II, theorem 2.2]{kulkarni-2012}.
\end{proof}

De este resultado obtenemos dos sencillas consecuencias:

\begin{corolario}
    \label{cor:fmp}
    La variable aleatoria $X_n$ se distribuye según la función masa de probabilidad descrita por el vector aleatorio 
    $$
    a^{(n)} = P^n X_0.
    $$
\end{corolario}

\begin{corolario}
    \label{cor:Pnm}
    $$
    P[X_{n+m}=j|X_n=i,X_{n-1}=i_{n-1},\dots,X_0=i_0] = P[X_{n+m}=j|X_n=i]=p_{ij}^{(m)},
    $$
$j,i,i_{n-1},\dots,i_0\in S$.
\end{corolario}

Seguidamente, presentamos una ecuación importante en este ámbito.

\begin{teorema}[Ecuación de Chapman-Kolmogorov]
    Sea $\{X_n,n\geq 0\}$ una cadena de Markov homogénea, entonces las probabilidades de transición en $n$ pasos satisfacen la siguiente igualdad, denominada ecuación de Chapman-Kolmogorov.
    \begin{equation}
        \label{eq:chapman-kolmogorov}
        p_{ij}^{(n+m)}=\sum_{k=1}^N p_{ik}^{(n)}p_{kj}^{(m)}.
    \end{equation} 
\end{teorema}
\begin{proof}
    \begin{equation*}
        \begin{split}
            p_{ij}^{(n+m)} &= P[X_{n+m}=j|X_0=i] \\
            &= \sum_{k=1}^N P[X_{n+m}=j|X_n=k,X_0=i]\,P[X_n=k|X_0=i]\text{ (th. de la prob. total)}\\
            &= \sum_{k=1}^N P[X_{n+m}=j|X_n=k]\,P[X_n=k|X_0=i]\text{ (corolario \ref{cor:Pnm})}\\
            &= \sum_{k=1}^N P[X_{m}=j|X_0=k]\,P[X_n=k|X_0=i]\text{ (por la homogeneidad)}\\
            &= \sum_{k=1}^N p_{ik}^{(n)} p_{kj}^{(m)}
        \end{split}
    \end{equation*}
\end{proof}

Si escribimos la ecuación (\ref{eq:chapman-kolmogorov}) en forma matricial, tenemos que
$$
P^{(n+m)}=P^{(n)}\cdot P^{(m)},
$$
lo cual es evidente teniendo en cuenta el teorema \ref{th:matriz-trans-n}. Intercambiando los roles de $n$ y $m$ llegamos a la conclusión de que las matrices $P^{(n)}$ y $P^{(m)}$ conmutan para todo $n,m\geq 0$. El teorema \ref{th:matriz-trans-n} es la clave del método para calcular las distribuciones transitorias, pues reduce el problema a potencias y multiplicaciones de matrices.

\begin{ejemplo}
    Tratemos ahora un ejemplo distinto. En este caso nos centraremos en las variaciones interprovinciales. La tabla \ref{tab:variaciones} muestra en cada celda el número de individuos que cambiaron su vivienda habitual desde la provincia indicada en la fila hacia la provincia indicada en la columna correspondiente (datos extraídos del INE: Instituto Nacional de Estadística).

    \begin{table}[h]
        \centering
        \begin{tabular}{cccc}\hline
            \textbf{Provincia} & \textbf{Alicante} & \textbf{Castellón} & \textbf{Valencia} \\ \hline\hline
        \textbf{Alicante}                  & 41.685                    & 484                         & 3.957                      \\ \hline
        \textbf{Castellón}                & 369                       & 11.059                      & 2.232                      \\ \hline
        \textbf{Valencia}                & 3.516                     & 2.903                       & 71.741 \\ \hline            
        \end{tabular}
        \caption{Variaciones interprovinciales en la comunidad valenciana (2021)}
        \label{tab:variaciones}
        \end{table}

        Por su parte, la tabla \ref{tab:poblacion} muestra la población de cada una de las provincias en el año 2021. 

        \begin{table}[h]
            \centering
            \begin{tabular}{cc}\hline
                \textbf{Provincia}  & \textbf{Población} \\ \hline\hline
                \textbf{Alicante} &  1881762 \\ \hline
                \textbf{Castellón} & 587064 \\ \hline
                \textbf{Valencia} & 2589312 \\ \hline
            \end{tabular}
            \caption{Población de las provincias de la comunidad valenciana (2021)}
            \label{tab:poblacion}
        \end{table}

        Con estos datos y asumiendo que la población total permanece constante, ¿podemos comprobar la población de cada una de las provincias de la Comunidad Valenciana en el año 2022? ¿Y predecir las que habrá en el año 2023?

        Antes de proceder al propio modelado, queremos mencionar que estos datos han sido manipulados y presentados utilizando el software estadístico \texttt{R}\footnote{Consúltese su página web \url{https://www.r-project.org/}.}. El archivo de `R Markdown' \texttt{software/ejemplo-migraciones.Rmd} 
        contiene el código fuente en \texttt{R} y algunas descripciones, mientras que el fichero \texttt{software/ejemplo-migraciones.html}, aunque tiene el mismo contenido, es un archivo compilado que es posible abrir con cualquier navegador web y en el que no es necesario ejecutar nada para visualizar las salidas de los distintos comandos. 

        Procedemos a modelar el problema como una cadena de Markov $\{X_n,n\geq0\}$, donde 
        $$X_n \equiv \text{Distribución de la población total de la Comunidad Valenciana en el año }2021+n.$$ 
        Esta cadena se construye sobre los estados 
        $$
        S=\{1\equiv\text{`Alicante'}, 2\equiv\text{`Castellón'},3\equiv\text{`Valencia'}\}.
        $$
        Podemos tomar una matriz asociada a la tabla \ref{tab:variaciones} y a partir de ella construir la matriz de transición de la cadena, teniendo en cuenta que de esta matriz la celda $(i,j)$ representa el número de migraciones de la provincia $i$ a la provincia $j$. Sin embargo, es claro que la tabla \ref{tab:variaciones} no verifica las condiciones de la proposición \ref{prop:propiedades-matrices-markov}, por lo que no podemos formar directamente una matriz estocástica. De igual manera, el vector cuyas componentes son las de la tabla \ref{tab:poblacion} no puede ser una función masa de probabilidad pues sus componentes no suman $1$. Por suerte, estos problemas pueden solucionarse rápidamente sin más que dividir cada fila de la tabla \ref{tab:variaciones} entre el total de cada fila y cada componente de la tabla \ref{tab:poblacion} entre la suma de las tres celdas. De esta forma, tenemos la siguiente matriz de transición $P$ y la distribución inicial $X_0$.
        \begin{align*}
            \label{eq:ejemplo-migraciones-matriz}
            P &= \begin{pmatrix}
                0.90372024 & 0.01049300 & 0.08578676 \\
                0.02701318 & 0.80959004 & 0.16339678 \\
                0.04498465 & 0.03714176 & 0.91787359
            \end{pmatrix}, & X_0 &= \begin{pmatrix}
                0.3720266 \\
                0.1160633 \\
                0.5119101
            \end{pmatrix}.
        \end{align*}
        Por tanto, para conocer la distribución poblacional del año 2022 y la de 2023 simplemente tenemos que aplicar el teorema \ref{th:matriz-trans-n} y el corolario \ref{cor:fmp} para $n=1$ y $n=2$. Así,
        \begin{align*}
            X_1 &= P X_0 = \begin{pmatrix}
                0.3813410 \\
                0.1876577 \\
                0.4909151
            \end{pmatrix}, & X_2 &= P^2 X_0 = \begin{pmatrix}
                0.3887086 \\
                0.2424410 \\
                0.4747224
            \end{pmatrix}.
        \end{align*}

        Por último, si lo que queremos es predecir la población (y no realmente su distribución), tendríamos que multiplicar estas distribuciones por la población total en 2021, obteniendo las poblaciones que recogemos en las tablas \ref{tab:predicciones}.

        \begin{table}[h]
            \centering
            \begin{tabular}{ccc}\hline
            \textbf{Provincia}          & \textbf{2022} & \textbf{2023} \\ \hline\hline
            \textbf{Alicante}   & 1.928.875,2   & 1.966.142     \\ \hline
            \textbf{Castellón} & 949.198,8     & 1.226.300     \\ \hline
            \textbf{Valencia}  & 2.483.116,1   & 2.401.211    \\ \hline
            \end{tabular}
            \caption{Predicciones de la població de las provincias de la C. Valenciana en 2022 y 2023}
            \label{tab:predicciones}
            \end{table}

            \cb{REVIEW no me termina de convencer cómo he redactado el ejemplo, no sé si le doy el rigor suficiente.}
        
\end{ejemplo}