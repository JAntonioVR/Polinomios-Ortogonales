%
% ────────────────────────────────────────────────────────────────────────── I ──────────
%   :::::: C A D E N A S   D E   M A R K O V : :  :   :    :     :        :          :
% ────────────────────────────────────────────────────────────────────────────────────
%

\cb{REVIEW: Nada más empezar. El título está bien así o lo llamo `procesos de Markov' o algo similar?}

Hasta este momento, en los dos primeros capítulos, nos hemos centrado totalmente en una introducción teórico-práctica a los polinomios ortogonales y sus principales propiedades, profundizando en las llamadas familias clásicas. En este capítulo explicaremos una teoría probabilística que, aparentemente, nada tiene que ver con los polinomios ortogonales, aunque estudiaremos la estrecha relación que hay entre ambas teorías en el capítulo \ref{chap:POyPNM}.

En concreto, analizaremos desde un punto de vista general los llamados \textit{procesos de Markov, procesos markovianos} o simplemente \textit{cadenas de Markov}. Estos modelos, basados en estados, tratan de explicar las probabilidades de los posibles cambios de estado basándose en un principio denominado \textit{propiedad de Markov}. Esta denominación tanto del modelo como de la propiedad se debe a Andrey Markov, matemático que fue el primero en estudiar, en la década de 1900, los procesos estocásticos con dicha propiedad, que posteriormente se popularizarían.

Nos centraremos principalmente en procesos discretos, es decir, consideramos que el tiempo se divide en instantes $n=0,1,2,\dots$, sin olvidar que existe una teoría análoga en la que el tiempo es continuo $t\in[0,\infty)$. Denominamos \textit{estado} a cualquiera de las situaciones en las que se puede encontrar el sistema en un instante determinado. Por ejemplo, pensemos en una región en la que hay $N$ ciudades y dividimos el tiempo en años. Asumimos que un individuo siempre se encuentra asentado en una de estas ciudades aunque hay posibilidad de que de un año a otro se mude a otra distinta. Etiquetamos cada una de las ciudades con un número: ciudad $1$, ciudad $2$,\dots,ciudad $N$.

De forma general, consideramos un espacio de estados finito que con frecuencia denotaremos como $S=\{1,\dots, N\}$ y dividimos el tiempo en instantes $n=0,1,2,\dots$. Llamemos $X_n\in S$ al estado del sistema en el instante $n$. La propiedad específica que consideró Markov consiste en asumir que, suponiendo que el sistema se encuentra en un estado concreto en un instante concreto, la probabilidad de que ocurra una transición en el siguiente instante depende única y exclusivamente del estado actual.

\begin{definicion}[Cadena de Markov]
    Un proceso estocástico $\{X_n,n\geq 0\}$ en un espacio de estados $S$ verifica la \textbf{propiedad markoviana} o \textbf{propiedad de Markov} si, para todo $n\in\N_0$ y $j,i,i_{n-1},\dots, i_0 \in S$:
    \begin{equation}
        \label{eq:prop-markow}
        P[X_{n+1}=j | X_n=i, X_{n-1}=i_{n-1}, \dots, X_0=i_0 ] = P[X_{n+1}=j | X_n=i].
    \end{equation}

    En caso de que el proceso cumpla la propiedad (\ref{eq:prop-markow}) se denominará \textbf{cadena de Markov discreta}.

    Una cadena de Markov $\{X_n, n\geq 0\}$ se llamará \textbf{homogénea} si, para todo $n\in\N_0$,
    \begin{equation}
        \label{eq:cad-homogenea}
        P[X_{n+1}=j|X_n=i] = P[X_1=j|X_0=i].
    \end{equation}
\end{definicion}

Es decir, la probabilidad de que en un instante $n+1$ el sistema se encuentre en el estado $j$ es independiente de lo que haya ocurrido en los instantes anteriores a $n$. Por ejemplo, aplicando esta propiedad al tiempo atmosférico podríamos afirmar que la probabilidad de que mañana llueva únicamente depende de si hoy ha llovido, sin tener en cuenta el clima de los días anteriores. En epidemiología, es como afirmar que el número de contagios de una enfermedad únicamente depende del número de contagios que haya habido el día anterior, independientemente del número de contagios de los días anteriores ni los posibles factores externos. Intuitivamente, no parece que esta suposición sea muy realista y no cabe esperar resultados precisos en predicciones futuras. Sin embargo, lo cierto es que es útil para hacernos una idea de lo que puede ocurrir a largo plazo con relativa exactitud y es muy utilizada a la hora de implementar medidas en ámbitos como la migración, la extinción de animales, uso de suelo, etc.

La probabilidad $P[X_{n+1}=j|X_n=i]$ se denomina \textbf{probabilidad de transición en un paso} de la cadena en el instante $n$. Si además la cadena es homogénea, este valor es el mismo para todo instante $n$, de ahí el término `homogénea'.

